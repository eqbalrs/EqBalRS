{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a3424",
   "metadata": {
    "id": "133a3424"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import functools\n",
    "import io\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from random import sample\n",
    "from typing import List, Optional, Tuple\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import numba \n",
    "from sklearn.metrics import ndcg_score\n",
    "from numba import njit\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e15135",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5e15135",
    "outputId": "a580029d-fc2f-483e-ce98-469c25203fb5"
   },
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('train_movieLens.csv')\n",
    "ratings_df.columns = ['UserID', 'MovieID', 'Rating']\n",
    "\n",
    "UserList = ratings_df['UserID'].values\n",
    "ItemList = ratings_df['MovieID'].values\n",
    "unique_users = np.unique(UserList)\n",
    "#print(ratings_df)\n",
    "print('md..',max(np.unique(ItemList)))\n",
    "Test_ratings_df = pd.read_csv('valid_movieLens.csv')\n",
    "Test_ratings_df.columns = ['UserID', 'MovieID', 'Rating']\n",
    "print(Test_ratings_df.shape)\n",
    "UserList_Test=Test_ratings_df['UserID'].values\n",
    "ItemList_Test=Test_ratings_df['MovieID'].values\n",
    "unique_users_Test=np.unique(UserList_Test)\n",
    "print('..',max(unique_users_Test))\n",
    "\n",
    "\n",
    "Full_ratings_df = pd.read_csv('movieLens_full.csv')\n",
    "Full_ratings_df.columns = ['UserID', 'MovieID', 'Rating']\n",
    "print(len(ratings_df))\n",
    "print(len(Test_ratings_df))\n",
    "print(len(Full_ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f0f73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e0f0f73",
    "outputId": "e10e38bb-61df-45a6-cf8a-11b6cbb0cffb"
   },
   "outputs": [],
   "source": [
    "all_r , p = ratings_df.shape\n",
    "print(all_r)\n",
    "all_r_Test , p = Test_ratings_df.shape\n",
    "K=20\n",
    "N = len(set(Full_ratings_df.UserID))+1\n",
    "M = len(set(Full_ratings_df.MovieID))+1\n",
    "print(N)\n",
    "print(M)\n",
    "print(\"No. of users : \",len(set(Full_ratings_df.UserID)))\n",
    "print(\"No. of Movies: \",len(set(Full_ratings_df.MovieID)))\n",
    "\n",
    "N_test1= max(set(Test_ratings_df.UserID))\n",
    "M_test1=max(set(Test_ratings_df.MovieID))\n",
    "print(N_test1)\n",
    "print(M_test1)\n",
    "Test_ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509ce43",
   "metadata": {
    "id": "4509ce43"
   },
   "outputs": [],
   "source": [
    "popular_df = pd.read_csv('movieLens_popular.csv')\n",
    "pop = popular_df.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4bd2e",
   "metadata": {
    "id": "a1b4bd2e"
   },
   "outputs": [],
   "source": [
    "nonpopular_df = pd.read_csv('movieLens_non_popular.csv')\n",
    "nonpop = nonpopular_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = {}\n",
    "\n",
    "for movie_no in range(M):\n",
    "    item_list[movie_no] = 0\n",
    "    \n",
    "for index, row in ratings_df.iterrows():\n",
    "    idMovie = row['MovieID']\n",
    "    item_list[idMovie]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Test_item_list = {}\n",
    "for movie_no in range(M_test1+2):\n",
    "    Test_item_list[movie_no] = 0\n",
    "        \n",
    "        \n",
    "for index, row in Test_ratings_df.iterrows():\n",
    "    idMovie = row['MovieID']\n",
    "    \n",
    "    Test_item_list[idMovie]+=1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc6739",
   "metadata": {
    "id": "fdbc6739"
   },
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.pivot( 'UserID' , 'MovieID' , 'Rating').fillna(0)\n",
    "ratings_df = np.array(ratings_df)\n",
    "\n",
    "Test_ratings_df = Test_ratings_df.pivot( 'UserID' , 'MovieID' , 'Rating').fillna(0)\n",
    "Test_ratings_df = np.array(Test_ratings_df)\n",
    "\n",
    "print(Test_ratings_df.shape)\n",
    "\n",
    "N_test,M_test= Test_ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14570981",
   "metadata": {
    "id": "14570981"
   },
   "outputs": [],
   "source": [
    "dictt = []\n",
    "for i in range(M):#3666\n",
    "    if [i] in pop:\n",
    "        dictt.append(1)\n",
    "    else:\n",
    "        dictt.append(0)\n",
    "dictt = np.array(dictt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e251a",
   "metadata": {
    "id": "4b6e251a"
   },
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def m_f(R, P, Q, K,dictt, steps=100, alpha=0.000128, beta = 0.04): #function for matrix factorization\n",
    "  m_error = []\n",
    "  pm_error = []\n",
    "  npm_error = []\n",
    "  biasm = []\n",
    "  #ARP_ = []\n",
    "\n",
    "  Q = Q.T #taking transpose\n",
    " # print('Step A')\n",
    "  for step in range(steps):\n",
    "   # if(step%8 == 0):\n",
    "    #  print(\"====\",step)\n",
    "    for i in range(N): #for every row\n",
    "      for j in range(M): #for every column\n",
    "        if R[i][j] > 0: #if user has rated the item\n",
    "          eij = R[i][j] - np.dot(P[i,:] , Q[:,j]) #error = actual rating - predicted rating\n",
    "          #calculate gradient with alpha and beta parameter\n",
    "          for k in range(K): #for kth feature\n",
    "            P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j]  - beta*P[i][k] )\n",
    "            Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k]  - beta*Q[k][j] )\n",
    "    #print(\" P :\",P)\n",
    "    #print(\" Q :\",Q)\n",
    "    eR = np.dot(P,Q)\n",
    "    e = 0\n",
    "    count = 0\n",
    "    np_count = 0\n",
    "    np_error = 0\n",
    "    p_error = 0\n",
    "    p_count = 0\n",
    "    #print('Step B')\n",
    "    for i in range(N):#prediction\n",
    "      for j in range(M):\n",
    "        if R[i][j]> 0:\n",
    "            #print(R[i][j])\n",
    "            err = np.round(pow(R[i][j] - np.dot(P[i,:],Q[:, j]), 2) , 3)\n",
    "\n",
    "            if dictt[j] == 0:\n",
    "                np_count +=1\n",
    "                np_error += err\n",
    "            #if the item is popular\n",
    "            else:\n",
    "                p_count +=1\n",
    "                p_error += err\n",
    "            \n",
    "            count += 1\n",
    "            e = e + err\n",
    "          \n",
    "            \n",
    "\n",
    "\n",
    "    #print(\"main error : \",np.round(np.sqrt(e / count) ,3))\n",
    "    m_error.append(np.round((e / count) ,3))\n",
    "\n",
    "    #print(\"loss on popular items : \",np.round_(np.sqrt(p_error/p_count) , 3))\n",
    "    pm_error.append(np.round((p_error/p_count) , 3))\n",
    "\n",
    "    #print(\"loss on non popular items : \",np.round_(np.sqrt(np_error/np_count) , 3))\n",
    "    npm_error.append(np.round((np_error/np_count) , 3))\n",
    "\n",
    "    #print(\"popularity bias: \", np.round((  ((1/np_count)*np_error) - ((1/p_count)*p_error)),3) )\n",
    "    biasm.append(np.round((  ((1/np_count)*np_error) - ((1/p_count)*p_error)),3))\n",
    "\n",
    "\n",
    "  \n",
    "            \n",
    "        \n",
    "  return P,Q.T,m_error,pm_error,npm_error,biasm,eR\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d73910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit(parallel=False)\n",
    "def calc_ndcg_score(y_true, y_score):\n",
    "\n",
    "    y_max_sorted = y_true[y_true.argsort()[::-1]]\n",
    "    y_true_sorted = y_true[y_score.argsort()[::-1]]\n",
    "\n",
    "    k = y_true.shape[0]\n",
    "   \n",
    "\n",
    "    dcg_score = y_true_sorted[0] - 1\n",
    "    for i in np.arange(1, k):\n",
    "        dcg_score += y_true_sorted[i] / np.log2(i + 1)\n",
    "\n",
    "    max_score =2**(y_max_sorted[0])- 1\n",
    "    for i in np.arange(1, k):\n",
    "        max_score += y_max_sorted[i] / np.log2(i + 1)\n",
    "    \n",
    "    if max_score!=0:\n",
    "        ndcg = dcg_score / max_score\n",
    "    else:\n",
    "        ndcg = 0 \n",
    "    return ndcg \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def calcARP(UserList,ItemList,unique_users,eR,R):\n",
    "    \n",
    "    arp_new = 0\n",
    "    \n",
    "    w_count = 0 \n",
    "    ndcg_users = []\n",
    "    cnt = 0 \n",
    "    for u in unique_users:\n",
    "        pred_user = []\n",
    "        arp_user= 0\n",
    "        for i,j in zip(UserList,ItemList):\n",
    "            if i ==u and i<N and j<M:\n",
    "                predRating = eR[i][j]\n",
    "                pred_user.append(tuple((j,predRating)))\n",
    "        pred_user=sorted(pred_user, key = lambda t: t[1])\n",
    "        pred_user.reverse()\n",
    "        pred_user=pred_user[:10]\n",
    "        \n",
    "        true_y=[]\n",
    "        pred_y=[]\n",
    "        \n",
    "        w_user = 0 \n",
    "        for each in pred_user:\n",
    "            w_i = len(np.where(ItemList==each[0])[0])\n",
    "            true_y.append(R[u][each[0]])\n",
    "            pred_y.append(each[1])\n",
    "            w_user+= w_i\n",
    "            \n",
    "        ndcg_score_user = calc_ndcg_score(np.array(true_y),np.array(pred_y))#ndcg_score([true_y],[pred_y])\n",
    "        ndcg_users.append(ndcg_score_user)\n",
    "        cnt +=1\n",
    "        w_count += w_user\n",
    "    deno = 10*len(UserList)*len(unique_users)\n",
    "   # print('Deno is ',deno)\n",
    "    arp_new = np.round(w_count /deno,7)\n",
    "    \n",
    "    sum_=0\n",
    "    for each in ndcg_users:\n",
    "        sum_+= each\n",
    "   # print('SUm is ',sum_,cnt)    \n",
    "    ndcg_final = sum_/cnt\n",
    "    #ndcg_final = #np.mean(ndcg_users)\n",
    "    \n",
    "    return arp_new,ndcg_final\n",
    "\n",
    "\n",
    "    \n",
    "@njit(parallel=False)\n",
    "def calcARP_Test(UserList_Test,ItemList_Test,unique_users_Test,eR_Test,Test_R):\n",
    "    \n",
    "    arp_new = 0\n",
    "    \n",
    "    w_count = 0 \n",
    "    ndcg_users = []\n",
    "    cnt = 0 \n",
    "    for u in unique_users_Test:\n",
    "        pred_user = []\n",
    "        arp_user= 0\n",
    "        for i,j in zip(UserList_Test,ItemList_Test):\n",
    "            if i ==u and i<N_test and j<M_test:\n",
    "                predRating = eR_Test[i][j]\n",
    "                pred_user.append(tuple((j,predRating)))\n",
    "        pred_user=sorted(pred_user, key = lambda t: t[1])\n",
    "        pred_user.reverse()\n",
    "        pred_user=pred_user[:10]\n",
    "        \n",
    "        true_y=[]\n",
    "        pred_y=[]\n",
    "        \n",
    "        w_user = 0 \n",
    "        for each in pred_user:\n",
    "            w_i = len(np.where(ItemList==each[0])[0])\n",
    "            true_y.append(Test_R[u][each[0]])\n",
    "            pred_y.append(each[1])\n",
    "            w_user+= w_i\n",
    "            \n",
    "        ndcg_score_user = calc_ndcg_score(np.array(true_y),np.array(pred_y))#ndcg_score([true_y],[pred_y])\n",
    "        ndcg_users.append(ndcg_score_user)\n",
    "        cnt +=1\n",
    "        w_count += w_user\n",
    "    deno = 10*len(UserList_Test)*len(unique_users_Test)\n",
    "   # print('Deno is ',deno)\n",
    "    arp_new = np.round(w_count /deno,7)\n",
    "    \n",
    "    sum_=0\n",
    "    for each in ndcg_users:\n",
    "        sum_+= each\n",
    "   # print('SUm is ',sum_,cnt)    \n",
    "    ndcg_final = sum_/cnt\n",
    "    #ndcg_final = #np.mean(ndcg_users)\n",
    "    \n",
    "    return arp_new,ndcg_final\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-efficiency",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N,M = ratings_df.shape\n",
    "K = 20\n",
    "print(\"N_users : \",N)\n",
    "print(\"N_items : \",M)\n",
    "print(\"N_Dimensions : \", K)\n",
    "#pred = {}\n",
    "R = np.array(ratings_df)\n",
    "Test_R = Test_ratings_df\n",
    "seeds = [0,100,200,300,400,500,600,700,800,900]\n",
    "\n",
    "\n",
    "list_pop_error=[]\n",
    "list_non_pop_error=[]\n",
    "list_ndcg=[]\n",
    "list_arp=[]\n",
    "list_error=[]\n",
    "list_bias=[]\n",
    "\n",
    "list_pop_error_test=[]\n",
    "list_non_pop_error_test=[]\n",
    "list_ndcg_test=[]\n",
    "list_arp_test=[]\n",
    "list_error_test=[]\n",
    "list_bias_test=[]\n",
    "for run in range(10):\n",
    "    np.random.seed(seeds[run])\n",
    "    random.seed(seeds[run])\n",
    "    Q = np.round( np.random.uniform(low =0.1 , high = 0.9, size = (M,K)) ,2) \n",
    "    P = np.round(np.random.uniform(low =0.1 , high = 0.9, size = (N,K)),2)\n",
    "\n",
    "    nP, nQ , m_error,pm_error,npm_error,biasm , eR= m_f(R,P,Q,K,dictt)\n",
    "\n",
    "    trainoverepoch = pd.DataFrame(list(zip(m_error , pm_error , npm_error , biasm )),\n",
    "               columns =['Overall_loss', 'Error on popular items' , 'Error on non-popular items' , 'Popularity bias' ])\n",
    "    #pred[run] = eR\n",
    "    trainoverepoch.to_csv('output_new_mf_reg_movielens_train_overepoch'+str(run)+'_.csv')\n",
    "    print(run)\n",
    " \n",
    "    ans = calcARP(UserList,ItemList,unique_users,eR,R)\n",
    "    ARP,NDCG = ans[0], ans[1]\n",
    "    trainoverrun = []\n",
    "    trainoverrun.append(m_error[-1])\n",
    "    trainoverrun.append(pm_error[-1])\n",
    "    trainoverrun.append(npm_error[-1])\n",
    "    trainoverrun.append( biasm[-1])\n",
    "    trainoverrun.append(np.round(ARP,6))\n",
    "    trainoverrun.append(np.round(NDCG,6))\n",
    "    print(trainoverrun)\n",
    "    list_pop_error.append(pm_error[-1])\n",
    "    list_non_pop_error.append(npm_error[-1])\n",
    "    list_ndcg.append(np.round(NDCG,6))\n",
    "    list_arp.append(np.round(ARP,6))\n",
    "    list_error.append(m_error[-1])\n",
    "    list_bias.append(biasm[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    testoverrun = []\n",
    "    \n",
    "    \n",
    "    nP = nP\n",
    "    nQ = nQ.T\n",
    "    #############################  Testing  ################################\n",
    "    Test_e = 0\n",
    "    Test_count = 0\n",
    "    Test_np_count = 0\n",
    "    Test_np_error = 0\n",
    "    Test_p_error = 0\n",
    "    Test_p_count = 0\n",
    "    \n",
    "    for i in range(N_test):#prediction\n",
    "      for j in range(M_test):\n",
    "        if Test_R[i][j]> 0:\n",
    "            #print(R[i][j])\n",
    "            #print('R i j ',Test_R[i][j])\n",
    "\n",
    "            Test_err = np.round(pow(Test_R[i][j] - np.dot(nP[i,:],nQ[:, j]), 2) , 3)\n",
    "            \n",
    "            \n",
    "            if dictt[j] == 0:\n",
    "                Test_np_count +=1\n",
    "                Test_np_error += Test_err\n",
    "            #if the item is popular\n",
    "            else:\n",
    "                Test_p_count +=1\n",
    "                Test_p_error += Test_err\n",
    "            \n",
    "            Test_count += 1\n",
    "            Test_e = Test_e + Test_err\n",
    "            \n",
    "    eR_Test= np.array(np.dot(nP,nQ))\n",
    "    ans = calcARP_Test(UserList_Test,ItemList_Test,unique_users_Test,eR_Test,Test_R)    #calcARP_Test(eR_Test,Test_R)\n",
    "    Test_ARP,NDCG_Test = ans[0],ans[1]\n",
    "        \n",
    "            \n",
    "    testoverrun.append(np.round((Test_e / Test_count) ,6))\n",
    "    testoverrun.append(np.round((Test_p_error/Test_p_count) , 6))\n",
    "    testoverrun.append(np.round((Test_np_error/Test_np_count) , 6))\n",
    "    testoverrun.append(np.round((  ((1/Test_np_count)*Test_np_error) - ((1/Test_p_count)*Test_p_error)),6))\n",
    "    testoverrun.append(np.round(Test_ARP,6))\n",
    "    testoverrun.append(np.round(NDCG_Test,6))\n",
    "    print('Test : ',testoverrun)\n",
    "    list_pop_error_test.append(np.round((Test_p_error/Test_p_count) , 6))\n",
    "    list_non_pop_error_test.append(np.round((Test_np_error/Test_np_count) , 6))\n",
    "    list_ndcg_test.append(np.round(NDCG_Test,6))\n",
    "    list_arp_test.append(np.round(Test_ARP,6))\n",
    "    list_error_test.append(np.round((Test_e / Test_count) ,6))\n",
    "    list_bias_test.append(np.round((  ((1/Test_np_count)*Test_np_error) - ((1/Test_p_count)*Test_p_error)),6))\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open('output_new_mf_reg_movieLens_train_overrun', 'w') as myfile:\n",
    "      wr = csv.writer(myfile)\n",
    "      wr.writerow(trainoverrun)\n",
    "      wr.writerow(testoverrun)\n",
    "\n",
    "print(np.mean(list_pop_error))\n",
    "print(np.mean(list_non_pop_error))\n",
    "print(np.mean(list_ndcg))\n",
    "print(np.mean(list_arp))\n",
    "print(np.mean(list_error))\n",
    "print(np.mean(list_bias))\n",
    "\n",
    "print()\n",
    "print(np.mean(list_pop_error_test))\n",
    "print(np.mean(list_non_pop_error_test))\n",
    "print(np.mean(list_ndcg_test))\n",
    "print(np.mean(list_arp_test))\n",
    "print(np.mean(list_error_test))\n",
    "print(np.mean(list_bias_test))\n",
    "\n",
    "print('-'*10)\n",
    "\n",
    "print(np.std(list_pop_error))\n",
    "print(np.std(list_non_pop_error))\n",
    "print(np.std(list_ndcg))\n",
    "print(np.std(list_arp))\n",
    "print(np.std(list_error))\n",
    "print(np.std(list_bias))\n",
    "print()\n",
    "print(np.std(list_pop_error_test))\n",
    "print(np.std(list_non_pop_error_test))\n",
    "print(np.std(list_ndcg_test))\n",
    "print(np.std(list_arp_test))\n",
    "print(np.std(list_error_test))\n",
    "print(np.std(list_bias_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     with open('output_mf_train_overrun', 'w') as myfile:\n",
    "#       wr = csv.writer(myfile)\n",
    "#       wr.writerow(trainoverrun)\n",
    "          \n",
    "\n",
    "    #train\n",
    "    #alpha=0.0023, beta = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93903581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5f354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd7b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MF_regularized_MovieLens.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
